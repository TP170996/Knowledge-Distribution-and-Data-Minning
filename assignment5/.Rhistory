setwd("C:/Users/prabh/Desktop/Stevens/fall_2020/kdd/assignment3")
df = read.csv('breast-cancer-wisconsin.data.csv',header=TRUE, sep=",")
#Here we see that the summary for only column F6 hasn't been calculated on account of non-numeric characters in the column
n <- as.numeric(as.character(df$F6))
df$F6 <- n
#Remove the rows with missing values
df <- na.omit(df)
#Convert labels to factor class
df$Class<- factor(df$Class , levels = c("2","4") , labels = c("Benign","Malignant"))
#Generate train and test in the ratio 70% to 30%
size <- sample(1:nrow(df), 0.7 * nrow(df))
nor <-function(x) { (x -min(x))/(max(x)-min(x))   }
##Run nomalization on first 4 coulumns of dataset because they are the predictors
norm <- as.data.frame(lapply(df[,c(2,3,4,5,6,7,8,9,10)], nor))
df2 = df['Class']
#train set
train <- norm[size,]
cl_train <- df2[size,]
##test set
test <- norm[-size,]
cl_test <- df2[-size,]
#load the package class
library(class)
#run knn function for k = 3
clf <- knn(train,test,cl=cl_train,k=3)
#create confusion matrix
conf_matrix <- table(clf, cl_test)
print(conf_matrix)
#Accuracy
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(conf_matrix)
#run knn function for k = 5
clf <- knn(train,test,cl=cl_train,k=5)
#create confusion matrix
conf_matrix <- table(clf, cl_test)
print(conf_matrix)
#Accuracy
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(conf_matrix)
#run knn function for k = 10
clf <- knn(train,test,cl=cl_train,k=5)
#create confusion matrix
conf_matrix <- table(clf, cl_test)
print(conf_matrix)
#Accuracy
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(conf_matrix)
rm(list=ls())
#reading the csv data
ReadCancerFile <- read.csv("C:/Users/prabh/Desktop/Stevens/fall_2020/kdd/assignment3/llbreast-cancer-wisconsin.data.csv")
#reading the csv data
ReadCancerFile <- read.csv("C:/Users/prabh/Desktop/Stevens/fall_2020/kdd/assignment3/breast-cancer-wisconsin.data.csv")
ReadCancerFile[ReadCancerFile=='?'] <- NA
ReadCancerFile
#deleting the empty value rows
c1 <- na.omit(ReadCancerFile)
#selecting 1st row and every 5th row
TestData <- c1[c(T,F,F,F,F),]
#selecting rest of data
TrainDeta <- c1[c(F,T,T,T,T),]
#using knn=1
k1 <- knn(TrainDeta[,2:10], TestData[,2:10], TrainDeta[,11], k=1)
k1
#prediction for knn=1
table1 <- table(Prediction=k1, Actual=TestData[,11])
accuracy1 <- (sum(diag(table1)))/sum(table1)
error1 <-(1-accuracy1)*100
error1
#using knn=2
k2 <- knn(TrainDeta[,2:10], TestData[,2:10], TrainDeta[,11], k=2)
k2
#prediction for knn=2
table2 <- table(Prediction=k2, Actual=TestData[,11])
accuracy2 <- (sum(diag(table2)))/sum(table2)
error2 <-(1-accuracy2)*100
error2
#using knn=5
k5 <- knn(TrainDeta[,2:10], TestData[,2:10], TrainDeta[,11], k=5)
k5
#prediction for knn=1
table5 <- table(Prediction=k5, Actual=TestData[,11])
accuracy5 <- (sum(diag(table5)))/sum(table5)
error5 <-(1-accuracy5)*100
error5
#using knn=10
k10 <- knn(TrainDeta[,2:10], TestData[,2:10], TrainDeta[,11], k=10)
k10
#prediction for knn=10
table10 <- table(Prediction=k10, Actual=TestData[,11])
accuracy10 <- (sum(diag(table10)))/sum(table10)
error10 <-(1-accuracy10)*100
error10
save.image("C:/Users/prabh/Desktop/Stevens/fall_2020/kdd/assignment3/tp.RData")
source('C:/Users/prabh/Desktop/Stevens/fall_2020/kdd/assignment3/hw_3.R')
View(TestData)
setwd("C:/Users/prabh/Desktop/Stevens/fall_2020/kdd/assignment3")
df = read.csv('breast-cancer-wisconsin.data.csv',header=TRUE, sep=",")
#Here we see that the summary for only column F6 hasn't been calculated on account of non-numeric characters in the column
n <- as.numeric(as.character(df$F6))
df$F6 <- n
#Remove the rows with missing values
df <- na.omit(df)
#Convert labels to factor class
df$Class<- factor(df$Class , levels = c("2","4") , labels = c("Benign","Malignant"))
#Generate train and test in the ratio 70% to 30%
size <- sample(1:nrow(df), 0.7 * nrow(df))
nor <-function(x) { (x -min(x))/(max(x)-min(x))   }
##Run nomalization on first 4 coulumns of dataset because they are the predictors
norm <- as.data.frame(lapply(df[,c(2,3,4,5,6,7,8,9,10)], nor))
df2 = df['Class']
#train set
train <- norm[size,]
cl_train <- df2[size,]
##test set
test <- norm[-size,]
cl_test <- df2[-size,]
#load the package class
library(class)
#run knn function for k = 3
clf <- knn(train,test,cl=cl_train,k=3)
#create confusion matrix
conf_matrix <- table(clf, cl_test)
print(conf_matrix)
#Accuracy
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(conf_matrix)
#run knn function for k = 5
clf <- knn(train,test,cl=cl_train,k=5)
#create confusion matrix
conf_matrix <- table(clf, cl_test)
print(conf_matrix)
#Accuracy
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(conf_matrix)
#run knn function for k = 10
clf <- knn(train,test,cl=cl_train,k=5)
#create confusion matrix
conf_matrix <- table(clf, cl_test)
print(conf_matrix)
#Accuracy
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(conf_matrix)
# set working directory
setwd("C:/Users/prabh/Desktop/Stevens/fall_2020/kdd/assignment4")
#Import package 'e1071' for Naive Bayes Classifier and class package
#install.packages("e1071")
#install.packages(class)
library(e1071)
library(class)
#Load Breast cancer data file CSV
df <- read.csv("breast-cancer-wisconsin.data.csv",na.string="?")
#Remove any row with a missing value in any of the columns.
df<-na.omit(df)
View(df)
#Converting the type of column F6 from character to numeric
df$F6<-as.integer(df$F6)
#Converting the Class into type factor
df$Class<- factor(df$Class , levels = c("2","4") , labels = c("Benign","Malignant"))
is.factor(df$Class)
newData<- df[2:11]
#70% of the sample size
smp_size <- floor(0.70 * nrow(newData))
#Set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(newData)), size = smp_size)
#Loading 70% Breast cancer record in training dataset
training <- newData[train_ind, ]
#Loading 30% Breast cancer in test dataset
test <- newData[-train_ind, ]
#Implementing NaiveBayes
model_naive<- naiveBayes(Class ~ ., data = training)
#Predicting target class for the Validation set
predict_naive <- predict(model_naive, test)
conf_matrix <- table(predict_nb=predict_naive,class=test$Class)
print(conf_matrix)
#Output of Naive Bayes Classifier
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(conf_matrix)
setwd("C:/Users/prabh/Desktop/Stevens/fall_2020/kdd/assignment5")
df = read.csv('breast-cancer-wisconsin.data.csv',header=TRUE, sep=",")
head(df, n=5)
#Summarizing each column (e.g. min, max, mean )
summary(df)
#Here we see that the summary for only column F6 hasn't been calculated on account of non-numeric characters in the column
n <- as.numeric(as.character(df$F6))
summary(n, na.rm = TRUE)
df$F6 <- n
summary(df, na.rm = TRUE)
#Check the number of rows before
nrow(df)
#Remove the rows with missing values
df <- na.omit(df)
#Check the number of rows after
nrow(df)
#Convert labels to factor class
df$Class<- factor(df$Class , levels = c("2","4") , labels = c("Benign","Malignant"))
#Check if factor class
is.factor(df$Class)
#Generate train and test in the ratio 70% to 30%
df<- df[2:11]
size <- floor(0.70 * nrow(df))
#Set the seed
set.seed(123)
random <- sample(seq_len(nrow(df)), size = size)
#70% data in train dataset
train <- df[random, ]
#30% data in test dataset
test <- df[-random, ]
#Implementing CART
cart <- rpart(Class ~ ., data = train, method = "class")
#Predicting class for test set
predicted <- predict(cart, test, type = "class")
print(length(predicted))
print(length(test$Class))
#Confusion Matrix
conf_matrix <- table(predicted,test$Class)
print(conf_matrix)
#Accuracy
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(conf_matrix)
librar'class'
library(class)
library(rpart)
summary(n, na.rm = TRUE)
library(class)
library(rpart)
rm(list = ls())
setwd("C:/Users/prabh/Desktop/Stevens/fall_2020/kdd/assignment5")
df = read.csv('breast-cancer-wisconsin.data.csv',header=TRUE, sep=",")
head(df, n=5)
#Summarizing each column (e.g. min, max, mean )
summary(df)
#Here we see that the summary for only column F6 hasn't been calculated on account of non-numeric characters in the column
n <- as.numeric(as.character(df$F6))
summary(n, na.rm = TRUE)
df$F6 <- n
summary(df, na.rm = TRUE)
#Check the number of rows before
nrow(df)
#Remove the rows with missing values
df <- na.omit(df)
#Check the number of rows after
nrow(df)
#Convert labels to factor class
df$Class<- factor(df$Class , levels = c("2","4") , labels = c("Benign","Malignant"))
#Check if factor class
is.factor(df$Class)
#Generate train and test in the ratio 70% to 30%
df<- df[2:11]
size <- floor(0.70 * nrow(df))
#Set the seed
set.seed(123)
random <- sample(seq_len(nrow(df)), size = size)
#70% data in train dataset
train <- df[random, ]
#30% data in test dataset
test <- df[-random, ]
#Implementing CART
cart <- rpart(Class ~ ., data = train, method = "class")
#Predicting class for test set
predicted <- predict(cart, test, type = "class")
print(length(predicted))
print(length(test$Class))
#Confusion Matrix
conf_matrix <- table(predicted,test$Class)
print(conf_matrix)
#Accuracy
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(conf_matrix)
